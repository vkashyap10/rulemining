{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "# Import MNIST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 835,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_X = np.zeros((10000,2))\n",
    "data_y = np.zeros((10000,1))\n",
    "import random\n",
    "\n",
    "for i in range(data_X.shape[0]):\n",
    "    data_X[i,0] = random.uniform(0, 1)\n",
    "    data_X[i,1] = random.uniform(0, 1)\n",
    "    if(data_X[i,0] >= 0.5 and data_X[i,1]>=0.5):\n",
    "        data_y[i] = 1\n",
    "    else:\n",
    "        data_y[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Parameters\n",
    "learning_rate = 0.01\n",
    "num_steps = 500\n",
    "batch_size = 200\n",
    "display_step = 100\n",
    "\n",
    "# Network Parameters\n",
    "n_hidden_1 = 1 #1st layer number of neurons\n",
    "#n_hidden_2 = 15 #2nd layer number of neurons\n",
    "num_input = 2 # MNIST data input (img shape: 28*28)\n",
    "num_classes = 1 # MNIST total classes (0-9 digits)\n",
    "\n",
    "# initialize intervals for via\n",
    "# [0,1] since sigmoid is used\n",
    "input_interval = np.zeros((2,num_input))\n",
    "input_interval[1,:] = input_interval[1,:] + 1\n",
    "\"\"\"\n",
    "input_interval = []\n",
    "for i in range(num_input):\n",
    "    input_interval.append([(0,255)])\n",
    "input_interval = np.array(input_interval)\n",
    "\"\"\"\n",
    "\n",
    "h1_interval = np.zeros((2,n_hidden_1))\n",
    "h1_interval[1,:] = h1_interval[1,:] + 1\n",
    "\"\"\"\n",
    "for i in range(n_hidden_1):\n",
    "    h1_interval.append([0,1])\n",
    "h1_interval = np.array(h1_interval)  \n",
    "\"\"\"\n",
    "h2_interval = np.zeros((2,n_hidden_2))\n",
    "h2_interval[1,:] = h2_interval[1,:] + 1\n",
    "\"\"\"\n",
    "h2_interval = []\n",
    "for i in range(n_hidden_2):\n",
    "    h2_interval.append([(0,1)])\n",
    "h2_interval = np.array(h2_interval)\n",
    "\"\"\"\n",
    "\n",
    "out_interval = np.zeros((2,num_classes))\n",
    "out_interval[1,:] = out_interval[1,:] + 1\n",
    "\"\"\"\n",
    "out_interval = []\n",
    "for i in range(num_classes):\n",
    "    out_interval.append([(0,1)])\n",
    "out_interval = np.array(out_interval)\n",
    "\"\"\"\n",
    "\n",
    "# tf Graph input\n",
    "X = tf.placeholder(\"float\", [None, num_input])\n",
    "Y = tf.placeholder(\"float\", [None, num_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 837,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.],\n",
       "       [1., 1.]])"
      ]
     },
     "execution_count": 837,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([num_input, n_hidden_1])),\n",
    "    #'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_1, num_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    #'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "def neural_net(x):\n",
    "    # Hidden fully connected layer with 256 neurons\n",
    "    layer_1 = tf.sigmoid(tf.add(tf.matmul(x, weights['h1']), biases['b1']))\n",
    "    # Hidden fully connected layer with 256 neurons\n",
    "    #layer_2 = tf.sigmoid(tf.add(tf.matmul(layer_1, weights['h2']), biases['b2']))\n",
    "    # Output fully connected layer with a neuron for each class\n",
    "    out_layer = tf.sigmoid(tf.matmul(layer_1, weights['out']) + biases['out'])\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct model\n",
    "logits = neural_net(X)\n",
    "\n",
    "# Define loss and optimizer\n",
    "#loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y))\n",
    "loss = -(Y * tf.log(logits+ 1e-12) + (1 - Y) * tf.log( 1 - logits + 1e-12))\n",
    "loss_op = tf.reduce_mean(tf.reduce_sum(loss, reduction_indices=[1]))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "# Evaluate model (with test logits, for dropout to be disabled)\n",
    "#correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "correct_pred = tf.equal(tf.greater_equal(logits, 0.5), tf.greater_equal(Y, 0.5))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 841,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[16, 13, 14, 9]"
      ]
     },
     "execution_count": 841,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.sample(range(30), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch(batch_size):\n",
    "    index = random.sample(range(data_X.shape[0]), batch_size)\n",
    "    return data_X[index],data_y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1, Minibatch Loss= 1.4192, Training Accuracy= 0.250\n",
      "Step 100, Minibatch Loss= 0.7360, Training Accuracy= 0.295\n",
      "Step 200, Minibatch Loss= 0.5726, Training Accuracy= 0.755\n",
      "Step 300, Minibatch Loss= 0.5315, Training Accuracy= 0.780\n",
      "Step 400, Minibatch Loss= 0.4476, Training Accuracy= 0.825\n",
      "Step 500, Minibatch Loss= 0.4637, Training Accuracy= 0.750\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.7556\n",
      "[[0.29510498]\n",
      " [0.15732087]\n",
      " [0.21682264]\n",
      " ...\n",
      " [0.23624547]\n",
      " [0.316915  ]\n",
      " [0.29958618]]\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " ...\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "\n",
    "    for step in range(1, num_steps+1):\n",
    "        batch_x, batch_y = next_batch(batch_size)\n",
    "        # Run optimization op (backprop)\n",
    "        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\n",
    "        if step % display_step == 0 or step == 1:\n",
    "            # Calculate batch loss and accuracy\n",
    "            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: batch_x,\n",
    "                                                                 Y: batch_y})\n",
    "            print(\"Step \" + str(step) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.3f}\".format(acc))\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Calculate accuracy for MNIST test images\n",
    "    logit,f_accuracy,f_weights,f_biases = sess.run([logits,accuracy,weights,biases], feed_dict={X: data_X,Y: data_y})\n",
    "    print(\"Testing Accuracy:\", f_accuracy)\n",
    "    \n",
    "    print(data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 856,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.399206\n"
     ]
    }
   ],
   "source": [
    "print(np.max(logit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def sigmoid(x):\n",
    "    if(x>10):\n",
    "        return 1\n",
    "    if(x<-30):\n",
    "        return 1e-12\n",
    "    return 1 / (1 + math.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "h1 = np.array(f_weights['h1'])\n",
    "#h2 = np.array(f_weights['h2'])\n",
    "out_w = np.array(f_weights['out'])\n",
    "b1 = np.array(f_biases['b1'])\n",
    "#b2 = np.array(f_biases['b2'])\n",
    "out_b = np.array(f_biases['out'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 846,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h1.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "def objective(x,w):\n",
    "    w = np.array(w)\n",
    "    b = w[-1]\n",
    "    w = w[:-1]\n",
    "    k = sigmoid(np.sum(x*w) + b)\n",
    "    return np.sum(k)\n",
    "def objective_max(x,w):\n",
    "    w = np.array(w)\n",
    "    b = w[-1]\n",
    "    w = w[:-1]\n",
    "    k = sigmoid(np.sum(x*w) + b)\n",
    "    return -np.sum(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 848,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward phase for via\n",
    "def forward():\n",
    "    for i in range(h1.shape[1]):\n",
    "        w = h1[:,i]\n",
    "        #w = np.hstack((h1[:,i],b1[i]))\n",
    "        w = tuple(np.hstack((w,b1[i])))\n",
    "        bnds = []\n",
    "        for j in range(input_interval.shape[1]):\n",
    "            bnds.append((input_interval[0,j],input_interval[1,j]))\n",
    "        x0 = (0,0)\n",
    "        bnds = np.array(bnds)\n",
    "        bnds = tuple(bnds)\n",
    "        print(w)\n",
    "        sol = minimize (objective,x0,(w,),bounds = bnds)\n",
    "        h1_interval[0,i] = sol['fun']\n",
    "        sol = minimize(objective_max,x0,(w,),bounds = bnds)\n",
    "        h1_interval[1,i] = abs(sol['fun'])\n",
    "        \n",
    "        \n",
    "    # out layer\n",
    "    for i in range(out_w.shape[1]):\n",
    "        w = out_w[:,i]\n",
    "        #w = np.hstack((h1[:,i],b1[i]))\n",
    "        w = tuple(np.hstack((w,out_b[i])))\n",
    "        bnds = []\n",
    "        for j in range(h1_interval.shape[1]):\n",
    "            bnds.append((h1_interval[0,j],h1_interval[1,j]))\n",
    "        x0 = np.zeros((h1_interval.shape[1]))\n",
    "        bnds = np.array(bnds)\n",
    "        bnds = tuple(bnds)\n",
    "        sol = minimize (objective,x0,(w,),bounds = bnds)\n",
    "        out_interval[0,i] = sol['fun']\n",
    "        sol = minimize(objective_max,x0,(w,),bounds = bnds)\n",
    "        out_interval[1,i] = abs(sol['fun'])\n",
    "    \"\"\"\n",
    "    for i in range(h2.shape[1]):\n",
    "        max_interval_limit = h2[:,i]*h1_interval[1,:]\n",
    "        min_interval_limit = h2[:,i]*h1_interval[0,:]\n",
    "        h2_interval[0,i] = sigmoid(np.sum(min_interval_limit)+b2[i])\n",
    "        h2_interval[1,i] = sigmoid(np.sum(max_interval_limit)+b2[i])\n",
    "    \n",
    "    for i in range(out_w.shape[1]):\n",
    "        max_interval_limit = out_w[:,i]*h1_interval[1,:]\n",
    "        min_interval_limit = out_w[:,i]*h1_interval[0,:]\n",
    "        if(max_interval_limit<min_interval_limit):\n",
    "            temp = min_interval_limit\n",
    "            max_interval_limit = min_interval_limit\n",
    "            min_interval_limit = temp\n",
    "        out_interval[0,i] = sigmoid(np.sum(min_interval_limit) + out_b[i])\n",
    "        out_interval[1,i] = sigmoid(np.sum(max_interval_limit) + out_b[i])\n",
    "    \"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 849,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-2.5877903, -2.3961053, 2.5599093)\n"
     ]
    }
   ],
   "source": [
    "forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.13674724],\n",
       "       [0.40090991]])"
      ]
     },
     "execution_count": 850,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bound(weights,interval,bias,mode):\n",
    "    A_ub = weights.T\n",
    "    ones = np.identity((weights.T).shape[0])\n",
    "    zeros = np.zeros(((weights.T).shape[0],(weights.T).shape[0]))\n",
    "    #A_ub = np.hstack((A_ub,ones,zeros))\n",
    "    b_ub = -np.log(1/interval[1,:] - 1) - bias\n",
    "    b_ub1 = -np.log(1/interval[0,:]-1) - bias\n",
    "    ones = -np.identity((weights.T).shape[0])\n",
    "    #A_ub1 = np.hstack((weights.T,zeros,ones))\n",
    "    A_ub = np.vstack((A_ub,-A_ub))\n",
    "    b_ub = np.hstack((b_ub,-b_ub1))\n",
    "    new_interval = np.zeros((A_ub.shape[1]))\n",
    "    bnds = []\n",
    "    for j in range(A_ub.shape[1]):\n",
    "        bnds.append((0,1))\n",
    "    bnds = tuple(bnds)\n",
    "    for i in range(A_ub.shape[1]):\n",
    "        c = np.zeros((A_ub.shape[1]))\n",
    "        if(mode==\"min\"):\n",
    "            c[i] = 1\n",
    "        else:\n",
    "            c[i] = -1\n",
    "        res = scipy.optimize.linprog(c,A_ub = A_ub,b_ub = b_ub,options=dict(tol=1e-8),bounds = bnds)\n",
    "        #print(res)\n",
    "        new_interval[i] = res['x'][i]\n",
    "    return new_interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 852,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "def backward():\n",
    "    max_bounds = bound(out_w,out_interval,out_b,\"max\")\n",
    "    h1_interval[1,:] = max_bounds\n",
    "    min_bounds = bound(out_w,out_interval,out_b,\"min\")\n",
    "    h1_interval[0,:] = min_bounds\n",
    "    #max_bounds = bound(h2,h2_interval,b2,\"max\")\n",
    "    #min_bounds = bound(h2,h2_interval,b2,\"min\")\n",
    "    max_bounds = bound(h1,h1_interval,b1,\"max\")\n",
    "    input_interval[1,:] = max_bounds\n",
    "    min_bounds = bound(h1,h1_interval,b1,\"min\")\n",
    "    input_interval[0,:] = min_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 853,
   "metadata": {},
   "outputs": [],
   "source": [
    "backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 854,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.],\n",
       "       [1., 1.]])"
      ]
     },
     "execution_count": 854,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 855,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.13674724],\n",
       "       [0.40090991]])"
      ]
     },
     "execution_count": 855,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
